{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import setred_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 150\n",
      "Labeled samples: 99\n",
      "Unlabeled samples: 51\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Simulate unlabeling 30% of the samples\n",
    "rng = np.random.RandomState(42)\n",
    "mask_unlabeled = rng.rand(len(y)) < 0.3\n",
    "y[mask_unlabeled] = -1  # unlabeled samples\n",
    "\n",
    "# Ensure input arrays are valid and safe to process\n",
    "X = check_array(X)\n",
    "y = check_array(y, ensure_2d=False, dtype=y.dtype.type)\n",
    "\n",
    "# Separate labeled and unlabeled samples\n",
    "X_label = X[y != y.dtype.type(-1)]\n",
    "y_label = y[y != y.dtype.type(-1)]\n",
    "X_unlabel = X[y == y.dtype.type(-1)]\n",
    "\n",
    "# Print results\n",
    "print(f\"Total samples: {len(y)}\")\n",
    "print(f\"Labeled samples: {len(y_label)}\")\n",
    "print(f\"Unlabeled samples: {len(X_unlabel)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import check_X_y\n",
    "\n",
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "y = [0, 1, 0]\n",
    "\n",
    "X_checked, y_checked = check_X_y(X, y)\n",
    "\n",
    "print(X_checked.shape)  # (3, 2)\n",
    "print(y_checked.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_df = pd.DataFrame(X_checked, columns=['feature1', 'feature2'])\n",
    "isinstance(X_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator:\n",
    "    def __init__(self, a, b):\n",
    "        \"\"\"Initialize the calculator with two numbers.\"\"\"\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def add(self):\n",
    "        \"\"\"Return the sum of the two stored numbers.\"\"\"\n",
    "        return self.a + self.b\n",
    "\n",
    "    def subtract(self):\n",
    "        \"\"\"Return the result of subtracting the second number from the first.\"\"\"\n",
    "        return self.a - self.b\n",
    "\n",
    "# Example usage\n",
    "calc = Calculator(10, 5)\n",
    "\n",
    "print(calc.add())      # Output: 15\n",
    "print(calc.subtract()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior_probability(y):\n",
    "    \"\"\"Calculate the priori probability of each label\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array-like of shape (n_samples,)\n",
    "        array of labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    class_probability: dict\n",
    "        dictionary with priori probability (value) of each label (key)\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    u_c = dict(zip(unique, counts))\n",
    "    instances = len(y)\n",
    "    for u in u_c:\n",
    "        u_c[u] = float(u_c[u] / instances)\n",
    "    return u_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with 100 values between 0 and 2\n",
    "y = np.random.choice([0, 1, 2], size=150)\n",
    "y_probabilities = calculate_prior_probability(y)\n",
    "y_ = np.random.choice([0, 1, 2], size=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(list(y_probabilities.keys()))\n",
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.searchsorted(np.array(list(y_probabilities.keys())), y_, sorter = sort_idx )\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_wrong = 1 - np.asarray(np.array(list(y_probabilities.values())))[sort_idx][idx]\n",
    "p_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(p_wrong, weights.shape[1]).shape[0]/y_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_state = np.random.RandomState(42)\n",
    "iid_random = random_state.binomial(\n",
    "                1, np.repeat(p_wrong, weights.shape[1]).reshape(weights.shape)\n",
    "            )\n",
    "np.repeat(p_wrong, weights.shape[1]).reshape(weights.shape)[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Train a base classifier\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Let's simulate U_ as 3 new samples from the dataset\n",
    "U_ = X[50:54]  # Shape: (3, 4)\n",
    "\n",
    "# Apply your code manually\n",
    "raw_predictions = clf.predict_proba(U_)\n",
    "predictions = np.max(raw_predictions, axis=1)       # Highest class probability for each sample\n",
    "class_predicted = np.argmax(raw_predictions, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(raw_predictions, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(raw_predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_variables = np.random.rand(100, 4)\n",
    "predictions = np.max(random_variables, axis=1)\n",
    "class_predicted = np.argmax(random_variables, axis=1)\n",
    "indexes = predictions.argsort()[-10:]  # Get indices of the top 3 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_ = np.array(['A', 'B', 'C'])\n",
    "class_predicted = np.array([2, 0, 1])  # Class indices\n",
    "indexes = [0, 2]                       # We're interested in the first and third\n",
    "\n",
    "# class_predicted[indexes] → [2, 1]\n",
    "# classes_[2] → 'C', classes_[1] → 'B'\n",
    "\n",
    "# Result:\n",
    "y_ = np.array(['C', 'B'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions.shape\n",
    "new_instance = np.array([1,2,3])\n",
    "new_instance = new_instance.reshape(1,3)\n",
    "np.concatenate((raw_predictions,new_instance), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Build kneighbors graph\n",
    "A = kneighbors_graph(X, n_neighbors=3, mode='distance', include_self=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to a NetworkX graph\n",
    "G = nx.from_scipy_sparse_array(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: use a layout (e.g., spring layout)\n",
    "pos = nx.spring_layout(G, seed=42)  # Optional: reproducible layout\n",
    "\n",
    "# Option 2: use actual data for positions (e.g., first two features)\n",
    "# pos = {i: X[i, :2] for i in range(X.shape[0])}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "nx.draw(G, pos, node_size=50, node_color=y, cmap=plt.cm.viridis, with_labels=False)\n",
    "plt.title(\"k-Nearest Neighbors Graph (k=3)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iweights = np.divide(1,weights, out=np.zeros_like(weights), where= weights!=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[weights != 0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use fixed seed for reproducibility\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "# 10 coin tosses with 30% chance of heads (1)\n",
    "samples = rng.binomial(n=1, p=np.array([0.3,0.7]), size=10)\n",
    "\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pwrong = np.random.rand(5)\n",
    "weights = weights[-30:,:]\n",
    "pwrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.searchsorted(np.array(list(y_probabilities.keys())), y_, sorter = sort_idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from sklearn.base import BaseEstimator\n",
    "from sslearn.wrapper import Setred\n",
    "\n",
    "print(inspect.getsource(Setred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Combined class labels\n",
    "pre_yL = np.array([0, 1, 0, 2, 1])\n",
    "print(\"Pre-labeled classes:\", pre_yL)\n",
    "# Construct the class contrast matrix\n",
    "C = (pre_yL[:, None] != pre_yL[None, :]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_yL[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_yL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def simulate_ji_matrix(p_wrong, weights, weights_sum, weights_square_sum, n_simulations, random_state):\n",
    "    n_instances, n_neighbors = weights.shape\n",
    "\n",
    "    # Precompute simulation probabilities\n",
    "    p_matrix = np.repeat(p_wrong, n_neighbors).reshape(weights.shape)\n",
    "\n",
    "    # Matrix to store all simulated ji values\n",
    "    ji_matrix = np.zeros((n_instances,n_simulations))\n",
    "\n",
    "    for s in range(n_simulations):\n",
    "        # Simulate binary decisions\n",
    "        iid_random = random_state.binomial(1, p_matrix)\n",
    "        \n",
    "        # Simulate test statistic\n",
    "        ji = (iid_random * weights).sum(axis=1)\n",
    "        ji_matrix[:, s] = ji\n",
    "\n",
    "        # (Optional for SETRED): Compute p-value and filtering condition\n",
    "        mu_h0 = p_wrong * weights_sum\n",
    "        sigma_h0 = np.sqrt((1 - p_wrong) * p_wrong * weights_square_sum)\n",
    "\n",
    "        z_score = np.divide((ji - mu_h0), sigma_h0, out=np.zeros_like(sigma_h0), where=sigma_h0 != 0)\n",
    "        oi = norm.sf(abs(z_score), mu_h0, sigma_h0)\n",
    "        to_add = (oi < 0.05) & (z_score < mu_h0)  # or use self.rejection_threshold\n",
    "\n",
    "        # If you're using to_add for filtering, handle it externally\n",
    "\n",
    "    return ji_matrix\n",
    "\n",
    "\n",
    "def compare_to_observed(jiobs, ji_matrix):\n",
    "    # Returns a count or proportion of times simulated ji > observed\n",
    "    return 1 - np.mean(jiobs[:,None] < ji_matrix, axis=1)  # count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Step 1: Define your simulated setup\n",
    "random_state = np.random.RandomState(42)\n",
    "n_instances = 5\n",
    "n_neighbors = 4\n",
    "n_simulations = 1000\n",
    "\n",
    "# Example weights between subjects (normally distances)\n",
    "weights = np.random.rand(n_instances, n_neighbors)\n",
    "\n",
    "# Probabilities of being wrong (say from prior distribution)\n",
    "p_wrong = np.random.uniform(0.1, 0.4, size=n_instances)\n",
    "\n",
    "# Precomputed stats used for normalization\n",
    "weights_sum = weights.sum(axis=1)\n",
    "weights_square_sum = (weights ** 2).sum(axis=1)\n",
    "\n",
    "# Step 2: Create observed test statistic\n",
    "# Simulate one Bernoulli draw as if observed\n",
    "p_matrix = np.repeat(p_wrong, n_neighbors).reshape(weights.shape)\n",
    "iid_observed = random_state.binomial(1, p_matrix)\n",
    "ji_obs = (iid_observed * weights).sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation and comparison\n",
    "ji_sim = simulate_ji_matrix(p_wrong, weights, weights_sum, weights_square_sum,\n",
    "                            n_simulations=2, random_state=random_state)\n",
    "\n",
    "ji_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ji_obs[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ji_obs[:, None] < ji_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ji_obs[:, None] < ji_sim).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_simulated = np.mean(jiobs[:, None] < ji_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "counts = compare_to_observed(ji_obs, ji_sim)\n",
    "\n",
    "# Print results\n",
    "print(\"Observed ji:\", ji_obs)\n",
    "print(\"Simulated ji (first 5):\\n\", ji_sim[:5])\n",
    "print(\"Counts where simulated > observed:\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts < 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jfja_dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
